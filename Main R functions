######################################################### Below are the customized R codes used in this paper ##########################################################################



################################################## Revised Adjusted Kaplan-Meier Estimator  ##################################################
##############################################################################################################################################

 # Input:
  #   times     : residual times
  #   failures   : event indicator (1 = event, 0 = censored)
  #   variable   : treatment indicator (1 = treated, 0 = control)
  #   weights   : IPTW weights; If NULL, then the function reduces to Kaplan-Meier estimator

revisedAKME=function (times, failures, variable, weights)
{

    if (sum(weights <= 0) > 0) {
      print("Error weights must be superior to 0")
    }
    else {
      if (sum(failures != 0 & failures != 1) > 0) {
        print("Error failures must be a vector of 0 or 1")
      }
      else {
        if (is.null(weights)) {
          .w <- rep(1, length(times))
        }
        else {
          .w <- weights
        }
        .data <- data.frame(t = times, f = failures,
                            v = variable, w = .w)
        .data <- .data[!is.na(.data$v), ]
        Table <- data.frame(times = NULL, n.risk = NULL,
                            n.event = NULL, survival = NULL, variable = NULL)
        for (i in unique(variable)) {
          .d <- .data[.data$v == i, ]
          .tj <- c(-9999, sort(unique(.d$t[.d$f == 1])))
          .dj <- sapply(.tj, function(x) {
            sum(.d$w[.d$t == x & .d$f == 1])
          })
          .nj <- sapply(.tj, function(x) {
            sum(.d$w[.d$t >= x])
          })
          .st <- cumprod((.nj - .dj)/.nj)
          Table <- rbind(Table, data.frame(times = .tj,
                                           n.risk = .nj, n.event = .dj, survival = .st,
                                           variable = i))
        }
        return(Table)
      }
    }
 
}


#################################################### Link function for Propensity Score (logistic regression model) ##############################################################
#################################################################################################################################################################################
G.link=function(u){
output=ifelse(u>=0,1/(1 + exp(-u)),exp(u)/(1 + exp(u)))
return(output)
}





################################################## Function to calculate the conditional mean used for imputation  ##############################################################
#####################################################################################################################################################################################

calculate_conditional_mean <- function(r, error_t, jump, survival_fun) {
  # locate t_j >= r
  loc <- which(error_t >= r)
  if (length(loc) == 0) return(0)
  A <- sum(error_t[loc] * jump[loc])
  B <- survival_fun(r)                # S(r)
  if (is.na(B) || B <= 0) return(0)
  return(A / B)
}


####################################################### Imputation function for imputing the censored log survival time #######################################################################################
###############################################################################################################################################################################################################
# Input:
  #   obs_time     : observed log survival time
  #   delta        : event indicator (1 = event, 0 = censored)
  #   cov_z        : treatment indicator (1 = treated, 0 = control)
  #   cov_x        : covariates considered in the AFT model
  #   old_beta     : parameters beta related to covariates in the AFT model
  #   old_gamma    : parameter gamma related to treatment cov_z
  #   res_akm      : the adjusted Kaplan-Meier function

impute_survival_times <- function(obs_time, delta, cov_z, cov_x, old_beta, old_gamma, res_akm) {
  N_size <- length(obs_time)
  XB <- as.vector(cov_x %*% old_beta)     # XB_i = sum(Beta * X_i)
  imputed_time <- numeric(N_size)

  # Residuals (for threshold comparisons)
  # For treated, residual = obs - XB - gamma; for control res = obs - XB
  res_all <- obs_time - XB - old_gamma * cov_z

  # Extract times and survival by variable
  times1 <- res_akm$times[res_akm$variable == 1]
  S1     <- res_akm$survival[res_akm$variable == 1]

  times0 <- res_akm$times[res_akm$variable == 0]
  S0     <- res_akm$survival[res_akm$variable == 0]

  # Recreate the CDF-based jumps exactly like original:
  CDF1 <- 1 - S1
  if (length(CDF1) >= 1) Jump1 <- c(CDF1[1], diff(CDF1)) else Jump1 <- numeric(0)

  CDF0 <- 1 - S0
  if (length(CDF0) >= 1) Jump0 <- c(CDF0[1], diff(CDF0)) else Jump0 <- numeric(0)

  # Create survival step functions the same way you originally did:
  # stepfun(times, c(1, S))  (default right = TRUE)
  survival_1 <- stepfun(times1, c(1, S1))
  survival_0 <- stepfun(times0, c(1, S0))

  # Case 1: uncensored => observed time
  imputed_time[delta == 1] <- obs_time[delta == 1]

  # Case 2: censored & treated (Z==1)
  idx_cens1 <- which(delta == 0 & cov_z == 1)
  if (length(idx_cens1) > 0 && length(times1) > 0) {
    # compute EE for each r = residual for treated subjects
    r_vals <- res_all[idx_cens1]   # these are obs - XB - gamma for Z=1
    EE1 <- vapply(r_vals, FUN.VALUE = numeric(1), FUN = function(r) {
      calculate_conditional_mean(r, error_t = times1, jump = Jump1, survival_fun = survival_1)
    })
    imputed_time[idx_cens1] <- XB[idx_cens1] + old_gamma + EE1
  } else if (length(idx_cens1) > 0) {
    # no mass in treated KM => EE = 0, impute XB + gamma
    imputed_time[idx_cens1] <- XB[idx_cens1] + old_gamma
  }

  # Case 3: censored & control (Z==0)
  idx_cens0 <- which(delta == 0 & cov_z == 0)
  if (length(idx_cens0) > 0 && length(times0) > 0) {
    r_vals0 <- obs_time[idx_cens0] - XB[idx_cens0]   # obs - XB for controls
    EE0 <- vapply(r_vals0, FUN.VALUE = numeric(1), FUN = function(r) {
      calculate_conditional_mean(r, error_t = times0, jump = Jump0, survival_fun = survival_0)
    })
    imputed_time[idx_cens0] <- XB[idx_cens0] + EE0
  } else if (length(idx_cens0) > 0) {
    imputed_time[idx_cens0] <- XB[idx_cens0]
  }

  return(imputed_time)
}




###################################################################### KM estimate for ACE theta(t) #########################################################################################################
###########################################################################################################################################################################################################

KM_fun<- function(t, ObsTime, Delta, CovZ, weights = NULL) {
  # ---------------------------------------------------------------
  # Purpose:
  #   Compute the difference in Kaplan–Meier survival curves
  #   between treated (CovZ = 1) and control (CovZ = 0) groups,
  #   and return the difference S1(t) - S0(t) evaluated at time t.
  #
  # Input:
  #   t         : time(s) at which to evaluate survival difference
  #   ObsTime   : observed time-to-event or censoring times in the log scale
  #   Delta     : event indicator (1 = event, 0 = censored)
  #   CovZ      : treatment indicator (1 = treated, 0 = control)
  #   weights   : 
  #
  # Output:
  #   Numeric vector of S1(t) - S0(t)
  # ---------------------------------------------------------------

  # --- check input lengths ---
  if (length(ObsTime) != length(Delta) || length(ObsTime) != length(CovZ)) {
    stop("ObsTime, Delta, and CovZ must have the same length.")
  }

  # --- call revisedAKME() to compute KM estimates ---
  Kaplan <- revisedAKME(times = ObsTime, failures = Delta,
                        variable = CovZ, weights = weights)

  # --- Build KM step functions for each group ---
  KM_1 <- stepfun(
    Kaplan$times[Kaplan$variable == 1],
    c(1, Kaplan$survival[Kaplan$variable == 1])
  )

  KM_0 <- stepfun(
    Kaplan$times[Kaplan$variable == 0],
    c(1, Kaplan$survival[Kaplan$variable == 0])
  )

  # --- Evaluate survival difference S1(t) - S0(t) ---
  diff_surv <- KM_1(log(t)) - KM_0(log(t))

  return(diff_surv)
}




###################################################### Doubly weighted estimator for ACE theta(t) ###############################################################
#################################################################################################################################################################
  # ---------------------------------------------------------------
  # Purpose:
  #   Compute the difference in survival curves
  #   between treated (CovZ = 1) and control (CovZ = 0) groups,
  #   and return the difference S1(t) - S0(t) evaluated at time t.
  #
  # Input:
  #   t         : time(s) at which to evaluate survival difference
  #   ObsTime   : observed time-to-event or censoring times in the log scale
  #   CovZ      : treatment indicator (1 = treated, 0 = control)
  #   Cen_delta  : Censor indicator (0 = event, 1 = censored)
  #   weights   : IPTW weight
  #
  # Output:
  #   Numeric vector of S1(t) - S0(t)


DW_fun <- function(t, ObsTime, CovZ, Cen_delta, weights) {
  if (t == 0) return(0)

  # KM for censoring process
  res.akm_Censor <- revisedAKME(
    times = ObsTime,
    failures = Cen_delta,
    variable = CovZ,
    weights = weights
  )

  # Build step functions
  Cen_survival_1 <- stepfun(
    res.akm_Censor$times[res.akm_Censor$variable == 1],
    c(1, res.akm_Censor$survival[res.akm_Censor$variable == 1])
  )
  Cen_survival_0 <- stepfun(
    res.akm_Censor$times[res.akm_Censor$variable == 0],
    c(1, res.akm_Censor$survival[res.akm_Censor$variable == 0])
  )

  # Evaluate at log(t)
  Q1 <- Cen_survival_1(ObsTime)
  Q0 <- Cen_survival_0(ObsTime)

  # Avoid division by zero
 MinQ1=ifelse(min(Q1)==0,min(Q1[-which(Q1==0)]),min(Q1))

 MinQ0=ifelse(min(Q0)==0,min(Q0[-which(Q0==0)]),min(Q0))

  a1 <- ifelse(Cen_survival_1(log(t)) == 0, MinQ1, Cen_survival_1(log(t)))
  a0 <- ifelse(Cen_survival_0(log(t)) == 0, MinQ0, Cen_survival_0(log(t)))

  # DW estimator
  term1 <- mean(CovZ * weights * (ObsTime > log(t)) / a1)
  term0 <- mean((1 - CovZ) * weights * (ObsTime > log(t)) / a0)

  return(term1 - term0)
}

DW_fun(t=0.1, ObsTime=FinalData$Y, CovZ=FinalData$treatment, Cen_delta=1-FinalData$Censor, weights=fit_out$IPTW) 





######################################################## G-formula estimator for ACE theta(t)  #########################################################################################################
##########################################################################################################################################################################################################
 # Purpose:
  #   Compute the difference in survival curves
  #   between treated (CovZ = 1) and control (CovZ = 0) groups,
  #   and return the difference S1(t) - S0(t) evaluated at time t.
  #
  # Input:
  #   t         : time(s) at which to evaluate survival difference
  #   ObsTime   : observed time-to-event or censoring times in the log scale
  #   Delta     : event indicator (1 = event, 0 = censored)
  #   CovZ      : treatment indicator (1 = treated, 0 = control)
  #   CovX      : covariates in the AFT model
  #   est_beta0  : estimated intercept term in the AFT model
  #   est_beta  : estimated beta related to covariates CovX in the AFT model
  #   est_gamma : estimated gamma related to treatment CovZ
  #   est_alpha:  estimated alpha related to covariates in the propensity score model
  #   weights   : IPTW weight
  #
  # Output:
  #   Numeric vector of S1(t) - S0(t)


G_formula_fun<- function(t,ObsTime,Delta, CovZ,CovX,est_beta0, est_beta, est_gamma,est_alpha, weights) {

  ## ---------------------------
  ## 1. Compute residuals
  ## ---------------------------
  residuals <- ObsTime -
    est_beta0 -
    as.vector(est_beta %*% t(CovX)) -
    est_gamma * CovZ



  ## ---------------------------
  ## 2. Weighted KM on residuals
  ## ---------------------------
  km_res <- revisedAKME(
    times = residuals,
    failures = Delta,
    variable = CovZ,
    weights = weights
  )

  ## Build step functions S1(r), S0(r)
  S1 <- stepfun(
    km_res$times[km_res$variable == 1],
    c(1, km_res$survival[km_res$variable == 1])
  )

  S0 <- stepfun(
    km_res$times[km_res$variable == 0],
    c(1, km_res$survival[km_res$variable == 0])
  )

  ## ----------------------------------
  ## 3. G-formula estimation: E[S1(k1) - S0(k2)]
  ## ----------------------------------
  if (t <= 0) return(0)

  k1 <- log(t) - est_beta0 -
        as.vector(est_beta %*% t(CovX)) -
        est_gamma

  k2 <- log(t) - est_beta0 -
        as.vector(est_beta %*% t(CovX))

  ## Evaluate survival difference
  g_val <- mean(S1(k1) - S0(k2))

  return(g_val)
}





################################################## Doubly Robust Estimator for ACE theta(t) #####################################################################################################
###########################################################################################################################################################################
# Purpose:
  #   Compute the difference in survival curves
  #   between treated (CovZ = 1) and control (CovZ = 0) groups,
  #   and return the difference S1(t) - S0(t) evaluated at time t.
  #
  # Input:
  #   t         : time(s) at which to evaluate survival difference
  #   ObsTime   : observed time-to-event or censoring times in the log scale
  #   Delta     : event indicator (1 = event, 0 = censored)
  #   CovZ      : treatment indicator (1 = treated, 0 = control)
  #   CovX      : covariates in the AFT model
  #   est_beta0  : estimated intercept term in the AFT model
  #   est_beta  : estimated beta related to covariates CovX in the AFT model
  #   est_gamma : estimated gamma related to treatment CovZ
  #   est_alpha:  estimated alpha related to covariates in the propensity score model
  #   est_ps    : estimated propensity score 
  #   weights   : IPTW weight
  #
  # Output:
  #   Numeric vector of S1(t) - S0(t)

DR_fun <- function(t,
                      ObsTime,
                      Delta,
                      CovZ,
                      CovX,
                      est_beta0,
                      est_beta,
                      est_gamma,
                      est_alpha,
                       est_ps,
                      weights) {


 if (t <= 0) return(DR_estimate = 0)
Cen_delta=1-Delta

 # KM for censoring process
  res.akm_Censor <- revisedAKME(
    times = ObsTime,
    failures = Cen_delta,
    variable = CovZ,
    weights = weights
  )

  # Build step functions
  Cen_survival_1 <- stepfun(
    res.akm_Censor$times[res.akm_Censor$variable == 1],
    c(1, res.akm_Censor$survival[res.akm_Censor$variable == 1])
  )
  Cen_survival_0 <- stepfun(
    res.akm_Censor$times[res.akm_Censor$variable == 0],
    c(1, res.akm_Censor$survival[res.akm_Censor$variable == 0])
  )



 # Evaluate at log(t)
  Q1 <- Cen_survival_1(ObsTime)
  Q0 <- Cen_survival_0(ObsTime)

  # Avoid division by zero
 MinQ1=ifelse(min(Q1)==0,min(Q1[-which(Q1==0)]),min(Q1))

 MinQ0=ifelse(min(Q0)==0,min(Q0[-which(Q0==0)]),min(Q0))


a1=ifelse(Cen_survival_1(log(t))==0,MinQ1,Cen_survival_1(log(t)))
a0=ifelse(Cen_survival_0(log(t))==0,MinQ0,Cen_survival_0(log(t)))

 ## ---------------------------
  ## Compute residuals
  ## ---------------------------
  residuals <- ObsTime-est_beta0-as.vector(est_beta %*% t(CovX))-est_gamma * CovZ

km_res <- revisedAKME(
    times = residuals,
    failures = Delta,
    variable = CovZ,
    weights = weights
  )

  ## Build step functions S1(r), S0(r)
  S1 <- stepfun(
    km_res$times[km_res$variable == 1],
    c(1, km_res$survival[km_res$variable == 1])
  )

  S0 <- stepfun(
    km_res$times[km_res$variable == 0],
    c(1, km_res$survival[km_res$variable == 0])
  )


comp1=(CovZ*weights*(ObsTime>log(t)))*(1/a1) ## done
comp2=(((CovZ-est_ps)*CovZ*Cen_delta*(ObsTime>log(t)))/(a1*est_ps))*S1(log(t)-est_beta0-as.vector(est_beta%*%t(CovX))-est_gamma)
comp3=(1-CovZ)*weights*(ObsTime>log(t))*(1/a0)
comp4=(((est_ps-CovZ)*(1-CovZ)*Cen_delta*(ObsTime>log(t)))/(a0*(1-est_ps)))*S0(log(t)-est_beta0-as.vector(est_beta%*%t(CovX)))

DR_estimate=mean((comp1-comp2)-(comp3-comp4))

return(DR_estimate)


}



###################################### Bootstrap function used to calculate the standard errors for all estimators ############################################################################################
###############################################################################################################################################################################################################

 # Input:
  #  data      : dataset 
  # covariates_logistic: covariate names in the dataset for the PS model (logistic regression model)
  # covariates_aft     : covariate names in the dataset for the AFT model
  # time_var:           : column name in the dataset for observed time in log scale
  # delta_var           : column name in the dataset for the event indicator
  # treat_var           : column name in the dataset for the treatment indicator
  #  times              : times at which to compute estimators
  # init_params         : initial values for parameters in the AFT model and Propensity score model
  # B                   : number of bootstrap
  # n_cores             : >1 to attempt parallel (mclapply; not on Windows)
  # verbose             : If TRUE, the code will show progress updates during the bootstrap.
  


bootstrap_pipeline <- function(data,
                               covariates_logistic,
                               covariates_aft,
                               time_var,  ## column name for the ovserved time
                               delta_var,
                               treat_var,
                               times,   # times at which to compute estimators
                               init_params,  ## initial values for bootstrap
                               B,
                               seed,
                               n_cores,   # >1 to attempt parallel (mclapply; not on Windows)
                               verbose) {

  set.seed(seed)
  n <- nrow(data)

  # Storage containers
  p_aft <- length(covariates_aft)
  p_log <- length(covariates_logistic)
  n_param <- p_aft + 1 + (p_log + 1)  # Beta + gamma + (alpha0 + alpha)
  
  # matrix for parameters (par vector returned by optim)
  par_store <- matrix(NA_real_, nrow = B, ncol = n_param)
  colnames(par_store) <- paste0("p", seq_len(n_param))

  # bootstrap storage for beta0
  beta0_store <- rep(NA_real_, B)

  # store estimator curves: rows = B, cols = length(times)
  KM_store <- matrix(NA_real_, nrow = B, ncol = length(times))
  DW_store <- matrix(NA_real_, nrow = B, ncol = length(times))
  G_store  <- matrix(NA_real_, nrow = B, ncol = length(times))
  DR_store <- matrix(NA_real_, nrow = B, ncol = length(times))

  # function to run one bootstrap iteration
  one_boot <- function(b) {
    if (verbose && b %% 10 == 0) message("Bootstrap iter: ", b, "/", B) ##verbose = TRUE, the code will show progress updates during the bootstrap.
    idx <- sample.int(n, replace = TRUE)
    dat_b <- data[idx, , drop = FALSE]

    # 1) fit via optim
    opt_b <- tryCatch({
      optim(par = init_params,
            fn = Loss_fun_BJ_logistic_fast,
            data = dat_b,
            covariates_logistic = covariates_logistic,
            covariates_aft = covariates_aft,
            time_var = time_var,
            delta_var = delta_var,
            treat_var = treat_var,
            return_components = FALSE)
    }, error = function(e) e)

    if (inherits(opt_b, "error")) {
      return(list(success = FALSE))
    }

    # 2) extract components using return_components=TRUE
    comps <- tryCatch({
      Loss_fun_BJ_logistic_fast(x = opt_b$par,
                                data = dat_b,
                                covariates_logistic = covariates_logistic,
                                covariates_aft = covariates_aft,
                                time_var = time_var,
                                delta_var = delta_var,
                                treat_var = treat_var,
                                return_components = TRUE)
    }, error = function(e) e)

    if (inherits(comps, "error")) return(list(success = FALSE))

    # 3) compute beta0
    beta0_b <- tryCatch({
      Estimate_beta0(comps)
    }, error = function(e) NA_real_)

    # 4) compute estimators at all times (use data indices from dat_b)
    # prepare inputs
    ObsTime_b <- dat_b[[time_var]]
    Delta_b   <- dat_b[[delta_var]]
    CovZ_b    <- dat_b[[treat_var]]
    if (is.factor(CovZ_b)) CovZ_b <- as.numeric(as.character(CovZ_b))
    # CovX for AFT: from comps$CovX_aft which was computed using dat_b
    CovX_aft_b <- comps$CovX_aft
    # weights & propensity
    IPTW_b <- comps$IPTW
    Pr_b   <- comps$Pr

    # compute estimators for each time
    KM_vec <- sapply(times, function(tt) {
      tryCatch({
        KM_fun(t = tt, ObsTime = ObsTime_b, Delta = Delta_b, CovZ = CovZ_b, weights = NULL)
      }, error = function(e) NA_real_)
    })

    DW_vec <- sapply(times, function(tt) {
      tryCatch({
        DW_fun(t = tt, ObsTime = ObsTime_b, CovZ = CovZ_b, Cen_delta = 1 - Delta_b, weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    G_vec <- sapply(times, function(tt) {
      tryCatch({
        G_formula_fun(t = tt,
                      ObsTime = ObsTime_b,
                      Delta = Delta_b,
                      CovZ = CovZ_b,
                      CovX = CovX_aft_b,
                      est_beta0 = beta0_b,
                      est_beta = comps$Beta,
                      est_gamma = comps$gamma,
                      est_alpha = comps$Alpha,
                      weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    DR_vec <- sapply(times, function(tt) {
      tryCatch({
        DR_fun(t = tt,
               ObsTime = ObsTime_b,
               Delta = Delta_b,
               CovZ = CovZ_b,
               CovX = CovX_aft_b,
               est_beta0 = beta0_b,
               est_beta = comps$Beta,
               est_gamma = comps$gamma,
               est_alpha = comps$Alpha,
               est_ps = Pr_b,
               weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    return(list(success = TRUE,
                par = opt_b$par,
                beta0 = beta0_b,
                KM = KM_vec,
                DW = DW_vec,
                G = G_vec,
                DR = DR_vec))
  } # end one_boot

  # Run bootstrap loop (parallel or serial)
  if (n_cores > 1 && .Platform$OS.type != "windows") {
    # use mclapply on Unix-like systems
    res_list <- parallel::mclapply(seq_len(B), one_boot, mc.cores = n_cores)
  } else {
    res_list <- lapply(seq_len(B), one_boot)
  }

  # Collect results
  success_idx <- which(sapply(res_list, function(x) is.list(x) && !is.null(x$success) && x$success))
  n_success <- length(success_idx)
  if (verbose) message("Bootstrap finished. Successful reps: ", n_success, "/", B)

  if (n_success == 0) stop("All bootstrap replicates failed. Check convergence or increase iterations / change inits.")

  for (i in seq_along(success_idx)) {
    r <- res_list[[ success_idx[i] ]]
    row <- success_idx[i]
    par_store[row, seq_along(r$par)] <- r$par
    beta0_store[row] <- r$beta0
    KM_store[row, ] <- r$KM
    DW_store[row, ] <- r$DW
    G_store[row, ]  <- r$G
    DR_store[row, ] <- r$DR
  }

  # Remove rows with all NA (failed reps)
  valid_par_rows <- which(rowSums(is.na(par_store)) < ncol(par_store))
  # Effective B
  effB <- length(valid_par_rows)

  # ---------- Summaries ----------
  # 1) Fit original sample to get point estimates (if not already)
  orig_fit <- optim(par = init_params,
                    fn = Loss_fun_BJ_logistic_fast,
                    data = data,
                    covariates_logistic = covariates_logistic,
                    covariates_aft = covariates_aft,
                    time_var = time_var,
                    delta_var = delta_var,
                    treat_var = treat_var,
                    return_components = FALSE)

  orig_comps <- Loss_fun_BJ_logistic_fast(x = orig_fit$par, data = data,
                                         covariates_logistic = covariates_logistic,
                                         covariates_aft = covariates_aft,
                                         time_var = time_var, delta_var = delta_var,
                                         treat_var = treat_var, return_components = TRUE)
  orig_beta0 <- Estimate_beta0(orig_comps)

  # param point estimates
  param_point <- orig_fit$par
  # bootstrap param samples (only valid rows)
  par_bs <- par_store[valid_par_rows, , drop = FALSE]
  beta0_bs <- beta0_store[valid_par_rows]

  # param summaries: mean, se (sd of bootstrap), 95% percentile CI, p-value (normal approx)
  #param_mean <- apply(par_bs, 2, mean, na.rm = TRUE)
  param_se   <- apply(par_bs, 2, sd, na.rm = TRUE)
  param_ci_low <- param_point - 1.96 * param_se
  param_ci_up  <- param_point + 1.96 * param_se


  param_pval <- 2 * (1 - pnorm(abs(param_point / param_se)))

  # beta0 summary
  beta0_point <- orig_beta0
  beta0_se <- sd(beta0_bs, na.rm = TRUE)
  beta0_ci_low <- beta0_point - 1.96 * beta0_se
  beta0_ci_up  <- beta0_point + 1.96 * beta0_se
  beta0_pval <- 2 * (1 - pnorm(abs(beta0_point / beta0_se)))

  # ---------- Estimator curves summaries ----------
  # Keep only valid bootstrap rows
  KM_bs <- KM_store[valid_par_rows, , drop = FALSE]
  DW_bs <- DW_store[valid_par_rows, , drop = FALSE]
  G_bs  <- G_store[valid_par_rows, , drop = FALSE]
  DR_bs <- DR_store[valid_par_rows, , drop = FALSE]

  # point estimates from original sample
  ObsTime_orig <- data[[time_var]]
  Delta_orig   <- data[[delta_var]]
  CovZ_orig    <- data[[treat_var]]
  if (is.factor(CovZ_orig)) CovZ_orig <- as.numeric(as.character(CovZ_orig))
  CovX_aft_orig <- orig_comps$CovX_aft
  IPTW_orig     <- orig_comps$IPTW
  Pr_orig       <- orig_comps$Pr

  KM_point <- sapply(times, function(tt) KM_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, weights = NULL))
  DW_point <- sapply(times, function(tt) DW_fun(tt, ObsTime_orig, CovZ_orig, Cen_delta = 1 - Delta_orig, weights = IPTW_orig))
  G_point  <- sapply(times, function(tt) G_formula_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, CovX_aft_orig,
                                                      est_beta0 = orig_beta0, est_beta = orig_comps$Beta,
                                                      est_gamma = orig_comps$gamma, est_alpha = orig_comps$Alpha,
                                                      weights = IPTW_orig))
  DR_point <- sapply(times, function(tt) DR_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, CovX_aft_orig,
                                                 est_beta0 = orig_beta0, est_beta = orig_comps$Beta,
                                                 est_gamma = orig_comps$gamma, est_alpha = orig_comps$Alpha,
                                                 est_ps = Pr_orig, weights = IPTW_orig))

  # compute bootstrap SD and percentile CI for curves


   curve_summary <- function(bs_mat, point_est) {
  # bs_mat : bootstrap matrix (B x n_times) for one estimator
  # point_est : numeric vector (length n_times) of point estimates from original sample

  if (ncol(bs_mat) != length(point_est)) {
    stop("Dimension mismatch: bs_mat columns must equal length(point_est).")
  }

  se_est <- apply(bs_mat, 2, sd, na.rm = TRUE)

  ci_low <- point_est - 1.96 * se_est
  ci_up  <- point_est + 1.96 * se_est

  list(point = point_est, se = se_est, ci_low = ci_low, ci_up = ci_up)
}


KM_sum <- curve_summary(KM_bs, KM_point)
DW_sum <- curve_summary(DW_bs, DW_point)
G_sum  <- curve_summary(G_bs,  G_point)
DR_sum <- curve_summary(DR_bs, DR_point)


  # assemble final output
  results <- list(
    call = list(times = times, B = B, seed = seed, n_cores = n_cores),
    orig = list(fit = orig_fit, comps = orig_comps, beta0 = orig_beta0,
                params = param_point),
    params_boot = list(point = param_point, se = param_se, ci_low = param_ci_low, ci_up = param_ci_up, pval = param_pval),
    beta0_boot = list( point = beta0_point, se = beta0_se, ci_low = beta0_ci_low, ci_up =beta0_ci_up, pval = beta0_pval),
    curves = list(
      times = times,
      ##point = list(KM = KM_point, DW = DW_point, G = G_point, DR = DR_point),
      bootstrap = list(KM = KM_sum, DW = DW_sum, G = G_sum, DR = DR_sum),
      all_boot = list(KM = KM_bs, DW = DW_bs, G = G_bs, DR = DR_bs)
    ),
    meta = list(effective_B = effB, successes = success_idx)
  )

  return(results)
}


##########################  The function is to populate the fitted results for the AFT model and Propensity Score model
######################################################################################################################################################################################################

 # Input:
  #  boot_out     : the fitted results from the bootstrap
  # covariates_aft     : covariate names in the dataset for the AFT model
  # covariates_logistic: covariate names in the dataset for the PS model (logistic regression model)


create_two_panel_outputs <- function(boot_out,
                                     covariates_aft,
                                     covariates_logistic) {

  # ==========================================================
  # Extract AFT-related parameters (beta0, beta, gamma)
  # ==========================================================
  # beta0
  beta0_point <- boot_out$beta0_boot$point
  beta0_se    <- boot_out$beta0_boot$se
  beta0_ci_l  <- boot_out$beta0_boot$ci_low
  beta0_ci_u  <- boot_out$beta0_boot$ci_up
  beta0_pval  <- boot_out$beta0_boot$pval

  # beta, gamma, alpha are stored together in params_boot
  param_point <- boot_out$params_boot$point
  param_se    <- boot_out$params_boot$se
  param_ci_l  <- boot_out$params_boot$ci_low
  param_ci_u  <- boot_out$params_boot$ci_up
  param_pval  <- boot_out$params_boot$pval

  # Structure of params_boot:
  #   [Beta (AFT)] + [Gamma (AFT)] + [Alpha (logistic)]

  n_beta  <- length(covariates_aft)
  n_alpha <- length(covariates_logistic) + 1   # logistic intercept + covariates

  # Indices
  beta_idx  <- 1:n_beta
  gamma_idx <- n_beta + 1
  alpha_idx <- (n_beta + 2):(n_beta + 1 + n_alpha)

  # ==========================================================
  # Panel A — AFT model output
  # ==========================================================
  aft_names <- c("Intercept_AFT", covariates_aft, "treatment")

  aft_estimates <- c(beta0_point,
                     param_point[beta_idx],
                     param_point[gamma_idx])

  aft_se  <- c(beta0_se,
               param_se[beta_idx],
               param_se[gamma_idx])

  aft_ci_l <- c(beta0_ci_l,
                param_ci_l[beta_idx],
                param_ci_l[gamma_idx])

  aft_ci_u <- c(beta0_ci_u,
                param_ci_u[beta_idx],
                param_ci_u[gamma_idx])

  aft_pval <- c(beta0_pval,
                param_pval[beta_idx],
                param_pval[gamma_idx])

  PanelA_AFT <- data.frame(
    Parameter = aft_names,
    Estimate  = aft_estimates,
    StdError  = aft_se,
    CI_lower  = aft_ci_l,
    CI_upper  = aft_ci_u,
    p_value   = aft_pval,
    row.names = NULL
  )

  # ==========================================================
  # Panel B — Logistic regression output
  # ==========================================================
  log_names <- c("Intercept_PS", covariates_logistic)

  PanelB_Logistic <- data.frame(
    Parameter = log_names,
    Estimate  = param_point[alpha_idx],
    StdError  = param_se[alpha_idx],
    CI_lower  = param_ci_l[alpha_idx],
    CI_upper  = param_ci_u[alpha_idx],
    p_value   = param_pval[alpha_idx],
    row.names = NULL
  )

  # Return two-panel output
  return(list(
    PanelA_AFT = PanelA_AFT,
    PanelB_Logistic = PanelB_Logistic
  ))
}







