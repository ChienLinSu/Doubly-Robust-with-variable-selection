
# Tamoxifen data analysis
# you should download the orginal dataset from NHLBI, which contains "GSE6532_LUMINAL.RData.gz", decompress into LUMINAL.RData


load("LUMINAL.RData")

############################################################### Extract the data and organize it to have the final dataset  #################################################################################               
##################################################################################################################################################################################################
## untreated group

trainY0 = data.frame(cbind("Y" = as.numeric(demo.untreated$t.rfs),
		    "Censor" = as.numeric(demo.untreated$e.rfs),
		    "Age" = as.numeric(demo.untreated$age),
		    "grade" = as.factor(match(demo.untreated$grade, c(1:3), nomatch = 0)),
		    "size" = as.numeric(demo.untreated$size)))
rownames(trainY0) = rownames(demo.untreated)

trainY0 = trainY0[!is.na(trainY0$Y) & !is.na(trainY0$Censor), ]

## treated group
trainY1 = data.frame(cbind("Y" = as.numeric(demo.tam$t.rfs),
		    "Censor" = as.numeric(demo.tam$e.rfs),
		    "Age" = as.numeric(demo.tam$age),
		    "grade" = as.factor(match(demo.tam$grade, c(1:3), nomatch = 0)),
		    "size" = as.numeric(demo.tam$size)))
rownames(trainY1) = rownames(demo.tam)
trainY1 = trainY1[!is.na(trainY1$Y) & !is.na(trainY1$Censor), ]
Clinical = rbind(trainY0, trainY1)


# get gene expression

sd_select =380
allx = rbind(data.untreated[match(rownames(trainY0), rownames(data.untreated)), ], 
			 data.tam[match(rownames(trainY1), rownames(data.tam)), ])

allsd = apply(allx, 2, sd)
allsd[is.na(allsd)] = 0
GeneExp = allx[, allsd >= sort(allsd, decreasing= TRUE)[sd_select] ]


Y = Clinical$Y
#trainX = cbind(GeneExp, Clinical$Age, Clinical$size, as.factor(Clinical$grade))
treatment = c(rep(0, nrow(trainY0)), rep(1, nrow(trainY1)))
#Censor = Clinical$Censor

Final.data=cbind(Clinical,treatment,GeneExp)
Final.data$treatment=ifelse(Final.data$treatment==1,"Tamoxifen","Control")
mean(Final.data$Censor) ## censoring rate

Final.data$Y=Final.data$Y/365  ## TRANSFORM days to years
Final.data$treatment=ifelse(Final.data$treatment=="Tamoxifen",1,0)
FinalData=Final.data[,c(1:6,which(colnames(Final.data)=="203824_at"))]
FinalData$GeneBinary=ifelse(FinalData$"203824_at"<= -0.063, 1,0) ## this group has better survival in the treatment group compared to the control group
FinalData$TrtGen=FinalData$GeneBinary*Final.data$treatment  ## interaction term between treatment and gene
FinalData$Y=log(FinalData$Y)  ## convert the observed time into log scale
FinalData$treatment=as.numeric(as.character(FinalData$treatment))

############################################################ Perform the Data Analysis based on the Proposed Doubly Weighted, G-formula and Doubly Robust Estimator  ###########################
################################################################################################################################################################################################

## Minimize the Loss Function to obtain parameter estimates in the AFT model and Propensity Score model

Loss_fun_BJ_logistic_fast=function(x,data,covariates_logistic,covariates_aft,time_var,delta_var,treat_var,return_components = FALSE){  ##specify the column name for each covariate and variable

  p_aft <- length(covariates_aft)
  p_logistic <- length(covariates_logistic)
  
  Beta <- x[1:p_aft]
  gamma <- x[p_aft + 1]
  Alpha <- x[(p_aft + 2):(p_aft + 2 + p_logistic)]

  CovX_aft <- as.matrix(data[, covariates_aft, drop = FALSE])
  CovX_log <- as.matrix(data[, covariates_logistic, drop = FALSE])

  CovZ <- data[[treat_var]]
  if (is.factor(CovZ)) {
  CovZ <- as.numeric(levels(CovZ))[CovZ]
  }
  ObsTime <- as.numeric(data[[time_var]])
  Delta <- as.numeric(data[[delta_var]])
  n <- nrow(data)

pi <- as.vector(Alpha %*% t(cbind(1, CovX_log)))
Pr=G.link(pi)

W<-as.vector((CovZ==1) * (1/Pr) + (CovZ==0) * (1/(1-Pr)))
error_time <- as.vector(ObsTime - (Beta %*% t(CovX_aft)) - gamma * CovZ)

res.akm <- revisedAKME(times=error_time, failures=Delta,variable=CovZ, weights=W)
imputed_time = impute_survival_times(obs_time=ObsTime, delta=Delta, cov_z=CovZ, cov_x=CovX_aft, old_beta=Beta, old_gamma=gamma, res.akm)

new_X=CovX_aft-matrix(rep(apply(CovX_aft,2,mean),n),n,length(apply(CovX_aft,2,mean)),byrow=TRUE)
Z_bar=mean(CovZ)
Obstime_bar=mean(imputed_time)
new_Z=(CovZ-Z_bar)
new_Obstime=(imputed_time-Obstime_bar)

component1=(new_Obstime-(Beta%*%t(new_X))-gamma*new_Z)^2
component2=(CovZ*log(exp(Alpha%*%t(cbind(1,CovX_log)))/(1+exp(Alpha%*%t(cbind(1,CovX_log))))))+((1-CovZ)*log(1-(exp(Alpha%*%t(cbind(1,CovX_log)))/(1+exp(Alpha%*%t(cbind(1,CovX_log)))))))

final_loss=((0.5*sum(component1))-sum(component2))/n

if (return_components) {
    return(list(
      loss = final_loss,
      Beta = Beta,
      gamma = gamma,
      Alpha = Alpha,
      imputed_time = imputed_time,
      Pr = Pr,
      IPTW=W,
      CovZ = CovZ,
      CovX_aft = CovX_aft,
      CovX_log = CovX_log
    ))
  } else {
    return(final_loss)
  }
}## for function


# Define covariates
cov_aft <- c("Age", "grade", "size", "GeneBinary","TrtGen")
cov_log <- c("Age", "grade", "size", "GeneBinary")

# Parameter vector (Beta + gamma + Alpha)
init_params <- c(-0.2,0.02,-0.3,-0.4,0.5,0.1,-3.1,0.12,-0.01,0.4,-0.2)

fit <- optim(
  par = init_params,
  fn = Loss_fun_BJ_logistic_fast,
  data =FinalData,
  covariates_logistic = cov_log,
  covariates_aft = cov_aft,
  time_var = "Y",
  delta_var = "Censor",
  treat_var = "treatment",return_components =FALSE)


fit_out <- Loss_fun_BJ_logistic_fast(
  x = fit$par,
  data = FinalData,
  covariates_logistic = cov_log,
  covariates_aft = cov_aft,
  time_var = "Y",
  delta_var = "Censor",
  treat_var = "treatment",
  return_components = TRUE
)


## function to estimate the intercept term in the AFT model
Estimate_beta0=function(fit_out){
estimate=mean(fit_out$imputed_time)-sum(fit_out$Beta*apply(fit_out$CovX_aft,2,mean))-fit_out$gamma*mean(fit_out$CovZ)
return(estimate)
}

## Estimate intercept term in the AFT model
Estimate_beta0(fit_out)




######################################## Bootstrap approach to obtain standard error estimation ########################################################################################################################
#######################################  - Parameter estimators for the AFT model and the Propensity Score model. 
######################################## - Average Causal Effect based on Doubly Weighted, G-formula and Doubly Robust estimators 
####################################################################################################################################################################################################################




bootstrap_pipeline <- function(data,
                               covariates_logistic,
                               covariates_aft,
                               time_var,  ## column name for the ovserved time
                               delta_var,
                               treat_var,
                               times,   # times at which to compute estimators
                               init_params,  ## initial values for bootstrap
                               B,
                               seed,
                               n_cores,   # >1 to attempt parallel (mclapply; not on Windows)
                               verbose) {

  set.seed(seed)
  n <- nrow(data)

  # Storage containers
  p_aft <- length(covariates_aft)
  p_log <- length(covariates_logistic)
  n_param <- p_aft + 1 + (p_log + 1)  # Beta + gamma + (alpha0 + alpha)
  
  # matrix for parameters (par vector returned by optim)
  par_store <- matrix(NA_real_, nrow = B, ncol = n_param)
  colnames(par_store) <- paste0("p", seq_len(n_param))

  # bootstrap storage for beta0
  beta0_store <- rep(NA_real_, B)

  # store estimator curves: rows = B, cols = length(times)
  KM_store <- matrix(NA_real_, nrow = B, ncol = length(times))
  DW_store <- matrix(NA_real_, nrow = B, ncol = length(times))
  G_store  <- matrix(NA_real_, nrow = B, ncol = length(times))
  DR_store <- matrix(NA_real_, nrow = B, ncol = length(times))

  # function to run one bootstrap iteration
  one_boot <- function(b) {
    if (verbose && b %% 10 == 0) message("Bootstrap iter: ", b, "/", B) ##verbose = TRUE, the code will show progress updates during the bootstrap.
    idx <- sample.int(n, replace = TRUE)
    dat_b <- data[idx, , drop = FALSE]

    # 1) fit via optim
    opt_b <- tryCatch({
      optim(par = init_params,
            fn = Loss_fun_BJ_logistic_fast,
            data = dat_b,
            covariates_logistic = covariates_logistic,
            covariates_aft = covariates_aft,
            time_var = time_var,
            delta_var = delta_var,
            treat_var = treat_var,
            return_components = FALSE)
    }, error = function(e) e)

    if (inherits(opt_b, "error")) {
      return(list(success = FALSE))
    }

    # 2) extract components using return_components=TRUE
    comps <- tryCatch({
      Loss_fun_BJ_logistic_fast(x = opt_b$par,
                                data = dat_b,
                                covariates_logistic = covariates_logistic,
                                covariates_aft = covariates_aft,
                                time_var = time_var,
                                delta_var = delta_var,
                                treat_var = treat_var,
                                return_components = TRUE)
    }, error = function(e) e)

    if (inherits(comps, "error")) return(list(success = FALSE))

    # 3) compute beta0
    beta0_b <- tryCatch({
      Estimate_beta0(comps)
    }, error = function(e) NA_real_)

    # 4) compute estimators at all times (use data indices from dat_b)
    # prepare inputs
    ObsTime_b <- dat_b[[time_var]]
    Delta_b   <- dat_b[[delta_var]]
    CovZ_b    <- dat_b[[treat_var]]
    if (is.factor(CovZ_b)) CovZ_b <- as.numeric(as.character(CovZ_b))
    # CovX for AFT: from comps$CovX_aft which was computed using dat_b
    CovX_aft_b <- comps$CovX_aft
    # weights & propensity
    IPTW_b <- comps$IPTW
    Pr_b   <- comps$Pr

    # compute estimators for each time
    KM_vec <- sapply(times, function(tt) {
      tryCatch({
        KM_fun(t = tt, ObsTime = ObsTime_b, Delta = Delta_b, CovZ = CovZ_b, weights = NULL)
      }, error = function(e) NA_real_)
    })

    DW_vec <- sapply(times, function(tt) {
      tryCatch({
        DW_fun(t = tt, ObsTime = ObsTime_b, CovZ = CovZ_b, Cen_delta = 1 - Delta_b, weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    G_vec <- sapply(times, function(tt) {
      tryCatch({
        G_formula_fun(t = tt,
                      ObsTime = ObsTime_b,
                      Delta = Delta_b,
                      CovZ = CovZ_b,
                      CovX = CovX_aft_b,
                      est_beta0 = beta0_b,
                      est_beta = comps$Beta,
                      est_gamma = comps$gamma,
                      est_alpha = comps$Alpha,
                      weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    DR_vec <- sapply(times, function(tt) {
      tryCatch({
        DR_fun(t = tt,
               ObsTime = ObsTime_b,
               Delta = Delta_b,
               CovZ = CovZ_b,
               CovX = CovX_aft_b,
               est_beta0 = beta0_b,
               est_beta = comps$Beta,
               est_gamma = comps$gamma,
               est_alpha = comps$Alpha,
               est_ps = Pr_b,
               weights = IPTW_b)
      }, error = function(e) NA_real_)
    })

    return(list(success = TRUE,
                par = opt_b$par,
                beta0 = beta0_b,
                KM = KM_vec,
                DW = DW_vec,
                G = G_vec,
                DR = DR_vec))
  } # end one_boot

  # Run bootstrap loop (parallel or serial)
  if (n_cores > 1 && .Platform$OS.type != "windows") {
    # use mclapply on Unix-like systems
    res_list <- parallel::mclapply(seq_len(B), one_boot, mc.cores = n_cores)
  } else {
    res_list <- lapply(seq_len(B), one_boot)
  }

  # Collect results
  success_idx <- which(sapply(res_list, function(x) is.list(x) && !is.null(x$success) && x$success))
  n_success <- length(success_idx)
  if (verbose) message("Bootstrap finished. Successful reps: ", n_success, "/", B)

  if (n_success == 0) stop("All bootstrap replicates failed. Check convergence or increase iterations / change inits.")

  for (i in seq_along(success_idx)) {
    r <- res_list[[ success_idx[i] ]]
    row <- success_idx[i]
    par_store[row, seq_along(r$par)] <- r$par
    beta0_store[row] <- r$beta0
    KM_store[row, ] <- r$KM
    DW_store[row, ] <- r$DW
    G_store[row, ]  <- r$G
    DR_store[row, ] <- r$DR
  }

  # Remove rows with all NA (failed reps)
  valid_par_rows <- which(rowSums(is.na(par_store)) < ncol(par_store))
  # Effective B
  effB <- length(valid_par_rows)

  # ---------- Summaries ----------
  # 1) Fit original sample to get point estimates (if not already)
  orig_fit <- optim(par = init_params,
                    fn = Loss_fun_BJ_logistic_fast,
                    data = data,
                    covariates_logistic = covariates_logistic,
                    covariates_aft = covariates_aft,
                    time_var = time_var,
                    delta_var = delta_var,
                    treat_var = treat_var,
                    return_components = FALSE)

  orig_comps <- Loss_fun_BJ_logistic_fast(x = orig_fit$par, data = data,
                                         covariates_logistic = covariates_logistic,
                                         covariates_aft = covariates_aft,
                                         time_var = time_var, delta_var = delta_var,
                                         treat_var = treat_var, return_components = TRUE)
  orig_beta0 <- Estimate_beta0(orig_comps)

  # param point estimates
  param_point <- orig_fit$par
  # bootstrap param samples (only valid rows)
  par_bs <- par_store[valid_par_rows, , drop = FALSE]
  beta0_bs <- beta0_store[valid_par_rows]

  # param summaries: mean, se (sd of bootstrap), 95% percentile CI, p-value (normal approx)
  #param_mean <- apply(par_bs, 2, mean, na.rm = TRUE)
  param_se   <- apply(par_bs, 2, sd, na.rm = TRUE)
  param_ci_low <- param_point - 1.96 * param_se
  param_ci_up  <- param_point + 1.96 * param_se


  param_pval <- 2 * (1 - pnorm(abs(param_point / param_se)))

  # beta0 summary
  beta0_point <- orig_beta0
  beta0_se <- sd(beta0_bs, na.rm = TRUE)
  beta0_ci_low <- beta0_point - 1.96 * beta0_se
  beta0_ci_up  <- beta0_point + 1.96 * beta0_se
  beta0_pval <- 2 * (1 - pnorm(abs(beta0_point / beta0_se)))

  # ---------- Estimator curves summaries ----------
  # Keep only valid bootstrap rows
  KM_bs <- KM_store[valid_par_rows, , drop = FALSE]
  DW_bs <- DW_store[valid_par_rows, , drop = FALSE]
  G_bs  <- G_store[valid_par_rows, , drop = FALSE]
  DR_bs <- DR_store[valid_par_rows, , drop = FALSE]

  # point estimates from original sample
  ObsTime_orig <- data[[time_var]]
  Delta_orig   <- data[[delta_var]]
  CovZ_orig    <- data[[treat_var]]
  if (is.factor(CovZ_orig)) CovZ_orig <- as.numeric(as.character(CovZ_orig))
  CovX_aft_orig <- orig_comps$CovX_aft
  IPTW_orig     <- orig_comps$IPTW
  Pr_orig       <- orig_comps$Pr

  KM_point <- sapply(times, function(tt) KM_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, weights = NULL))
  DW_point <- sapply(times, function(tt) DW_fun(tt, ObsTime_orig, CovZ_orig, Cen_delta = 1 - Delta_orig, weights = IPTW_orig))
  G_point  <- sapply(times, function(tt) G_formula_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, CovX_aft_orig,
                                                      est_beta0 = orig_beta0, est_beta = orig_comps$Beta,
                                                      est_gamma = orig_comps$gamma, est_alpha = orig_comps$Alpha,
                                                      weights = IPTW_orig))
  DR_point <- sapply(times, function(tt) DR_fun(tt, ObsTime_orig, Delta_orig, CovZ_orig, CovX_aft_orig,
                                                 est_beta0 = orig_beta0, est_beta = orig_comps$Beta,
                                                 est_gamma = orig_comps$gamma, est_alpha = orig_comps$Alpha,
                                                 est_ps = Pr_orig, weights = IPTW_orig))

  # compute bootstrap SD and percentile CI for curves


   curve_summary <- function(bs_mat, point_est) {
  # bs_mat : bootstrap matrix (B x n_times) for one estimator
  # point_est : numeric vector (length n_times) of point estimates from original sample

  if (ncol(bs_mat) != length(point_est)) {
    stop("Dimension mismatch: bs_mat columns must equal length(point_est).")
  }

  se_est <- apply(bs_mat, 2, sd, na.rm = TRUE)

  ci_low <- point_est - 1.96 * se_est
  ci_up  <- point_est + 1.96 * se_est

  list(point = point_est, se = se_est, ci_low = ci_low, ci_up = ci_up)
}


KM_sum <- curve_summary(KM_bs, KM_point)
DW_sum <- curve_summary(DW_bs, DW_point)
G_sum  <- curve_summary(G_bs,  G_point)
DR_sum <- curve_summary(DR_bs, DR_point)


  # assemble final output
  results <- list(
    call = list(times = times, B = B, seed = seed, n_cores = n_cores),
    orig = list(fit = orig_fit, comps = orig_comps, beta0 = orig_beta0,
                params = param_point),
    params_boot = list(point = param_point, se = param_se, ci_low = param_ci_low, ci_up = param_ci_up, pval = param_pval),
    beta0_boot = list( point = beta0_point, se = beta0_se, ci_low = beta0_ci_low, ci_up =beta0_ci_up, pval = beta0_pval),
    curves = list(
      times = times,
      ##point = list(KM = KM_point, DW = DW_point, G = G_point, DR = DR_point),
      bootstrap = list(KM = KM_sum, DW = DW_sum, G = G_sum, DR = DR_sum),
      all_boot = list(KM = KM_bs, DW = DW_bs, G = G_bs, DR = DR_bs)
    ),
    meta = list(effective_B = effB, successes = success_idx)
  )

  return(results)
}









FinalOutput=bootstrap_pipeline (data=FinalData,
                               covariates_logistic=cov_log,
                               covariates_aft=cov_aft,
                               time_var = "Y",  ## column name for the ovserved time
                               delta_var = "Censor",
                               treat_var = "treatment",
                               times =target.time,   # times at which to compute estimators
                               init_params=c(-0.2,0.02,-0.3,-0.4,0.5,0.1,-3.1,0.12,-0.01,0.4,-0.2),  ## initial values for bootstrap
                               B = 500,
                               seed = 639245,
                               n_cores = 1,   # >1 to attempt parallel (mclapply; not on Windows)
                               verbose = TRUE)






create_two_panel_outputs <- function(boot_out,
                                     covariates_aft,
                                     covariates_logistic) {

  # ==========================================================
  # Extract AFT-related parameters (beta0, beta, gamma)
  # ==========================================================
  # beta0
  beta0_point <- boot_out$beta0_boot$point
  beta0_se    <- boot_out$beta0_boot$se
  beta0_ci_l  <- boot_out$beta0_boot$ci_low
  beta0_ci_u  <- boot_out$beta0_boot$ci_up
  beta0_pval  <- boot_out$beta0_boot$pval

  # beta, gamma, alpha are stored together in params_boot
  param_point <- boot_out$params_boot$point
  param_se    <- boot_out$params_boot$se
  param_ci_l  <- boot_out$params_boot$ci_low
  param_ci_u  <- boot_out$params_boot$ci_up
  param_pval  <- boot_out$params_boot$pval

  # Structure of params_boot:
  #   [Beta (AFT)] + [Gamma (AFT)] + [Alpha (logistic)]

  n_beta  <- length(covariates_aft)
  n_alpha <- length(covariates_logistic) + 1   # logistic intercept + covariates

  # Indices
  beta_idx  <- 1:n_beta
  gamma_idx <- n_beta + 1
  alpha_idx <- (n_beta + 2):(n_beta + 1 + n_alpha)

  # ==========================================================
  # ✅ Panel A — AFT model output
  # ==========================================================
  aft_names <- c("Intercept_AFT", covariates_aft, "treatment")

  aft_estimates <- c(beta0_point,
                     param_point[beta_idx],
                     param_point[gamma_idx])

  aft_se  <- c(beta0_se,
               param_se[beta_idx],
               param_se[gamma_idx])

  aft_ci_l <- c(beta0_ci_l,
                param_ci_l[beta_idx],
                param_ci_l[gamma_idx])

  aft_ci_u <- c(beta0_ci_u,
                param_ci_u[beta_idx],
                param_ci_u[gamma_idx])

  aft_pval <- c(beta0_pval,
                param_pval[beta_idx],
                param_pval[gamma_idx])

  PanelA_AFT <- data.frame(
    Parameter = aft_names,
    Estimate  = aft_estimates,
    StdError  = aft_se,
    CI_lower  = aft_ci_l,
    CI_upper  = aft_ci_u,
    p_value   = aft_pval,
    row.names = NULL
  )

  # ==========================================================
  # ✅ Panel B — Logistic regression output
  # ==========================================================
  log_names <- c("Intercept_PS", covariates_logistic)

  PanelB_Logistic <- data.frame(
    Parameter = log_names,
    Estimate  = param_point[alpha_idx],
    StdError  = param_se[alpha_idx],
    CI_lower  = param_ci_l[alpha_idx],
    CI_upper  = param_ci_u[alpha_idx],
    p_value   = param_pval[alpha_idx],
    row.names = NULL
  )

  # Return two-panel output
  return(list(
    PanelA_AFT = PanelA_AFT,
    PanelB_Logistic = PanelB_Logistic
  ))
}


create_two_panel_outputs (boot_out=FinalOutput,
                                     covariates_aft=cov_aft,
                                     covariates_logistic=cov_log)







###### Boxplot for weight functions

Treatment=ifelse(fit_out$CovZ==1,"Tamoxifen","Control")
Boxplot_data=data.frame(wt=fit_out$IPTW,trt=Treatment)

bp<-ggplot(Boxplot_data, aes(x=Treatment, y=wt, fill=Treatment)) 
bp+geom_boxplot()+ stat_boxplot(geom ='errorbar') +
coord_cartesian(ylim = c(1,10))+  ylab("Weight")+scale_x_discrete(name ="Treatment")+theme_bw()



fit_out$IPTW
fit_out$CovZ




plotdata<- data.frame(Time=c(target.time,target.time,target.time,target.time), Difference=c(FinalOutput$curves$bootstrap$DR$point,adjdiff$diff,FinalOutput$curves$bootstrap$DW$point,FinalOutput$curves$bootstrap$KM$point),Estimator=c(rep("DR",length(target.time)),rep("AKME",length(target.time)),rep("DW",length(target.time)),rep("KM",length(target.time))), lower =c(FinalOutput$curves$bootstrap$DR$ci_low,adjdiff$ci_lower,FinalOutput$curves$bootstrap$DW$ci_low,FinalOutput$curves$bootstrap$KM$ci_low) , upper =c(FinalOutput$curves$bootstrap$DR$ci_up,adjdiff$ci_upper,FinalOutput$curves$bootstrap$DW$ci_up,FinalOutput$curves$bootstrap$KM$ci_up))


FinalOutput$curves$bootstrap$DR$point
FinalOutput$curves$bootstrap$DR$ci_low
FinalOutput$curves$bootstrap$DR$ci_up


FinalOutput$curves$bootstrap$DW$point
FinalOutput$curves$bootstrap$DW$ci_low
FinalOutput$curves$bootstrap$DW$ci_up


FinalOutput$curves$bootstrap$KM$point
FinalOutput$curves$bootstrap$KM$ci_low
FinalOutput$curves$bootstrap$KM$ci_up

plot_causal_effects <- function(data,
                                time_var = Time,
                                diff_var = Difference,
                                lower_var = lower,
                                upper_var = upper,
                                estimator_var = Estimator,
                                xlab = "Time (Years)",
                                ylab = "Average Causal Effect",
                                title = NULL) {

  ggplot(
    data = data,
    aes(
      x = {{ time_var }},
      y = {{ diff_var }},
      group = {{ estimator_var }},
      colour = {{ estimator_var }},
      fill = {{ estimator_var }},
      linetype = {{ estimator_var }}
    )
  ) +
    geom_line(linewidth = 0.9, na.rm = TRUE) +
    geom_ribbon(
      aes(ymin = {{ lower_var }}, ymax = {{ upper_var }}),
      alpha = 0.3,
      linetype = 0,
      na.rm = TRUE
    ) +
    scale_linetype_manual(values = c("longdash", "solid", "twodash", "dashed")) +
    theme_minimal(base_size = 14) +
    labs(x = xlab, y = ylab, title = title)
}
Figure<- plot_causal_effects(plotdata)
Figure

















